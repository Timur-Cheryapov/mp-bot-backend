# Chain of Thoughts Streaming API

## Overview

The MP Bot Backend provides a **Chain of Thoughts** streaming API that shows users the AI's complete reasoning process, including tool execution steps. This creates an engaging, transparent experience where users can follow the AI's decision-making in real-time.

## What Gets Sent

The streaming API sends **only** essential events with clean, structured data:

1. **AI message content** (as it's being generated)
2. **Tool execution notifications** (when AI decides to use tools)
3. **Processing status** (when tools complete)
4. **Completion signal** (when stream ends)
5. **Error handling** (if something goes wrong)

No internal LangChain events, raw metadata, or debug information is exposed to the frontend.

## Stream Format

The API uses **Server-Sent Events (SSE)** with the following event types:

### Event Types

#### 0. `conversationId` - Conversation Identifier (New conversations only)
Sent at the beginning of new conversation streams to provide the conversation ID.

```
event: conversationId
data: conv_12345abcdef
```

**Data**: String conversation ID

#### 1. `chunk` - AI Response Content
Contains the actual text content being generated by the AI.

```
event: chunk
data: "I'll help you check your Wildberries inventory."

event: chunk  
data: " Let me fetch your current product data..."
```

**Data**: JSON-stringified text content

#### 2. `tool_execution` - Tool Execution Started
Indicates the AI has decided to use tools and is starting execution.

```
event: tool_execution
data: {
  "message": "Let me fetch your Wildberries product data...",
  "toolCalls": ["wildberries_seller_products"]
}
```

**Data**: Object with user-friendly message and array of tool names

#### 3. `tool_complete` - Tool Execution Completed
Indicates tools have finished executing and results are being processed.

```
event: tool_complete
data: {
  "message": "Processing results..."
}
```

**Data**: Object with processing status message

#### 4. `end` - Stream Complete
Indicates the conversation stream has ended.

```
event: end
data: {}
```

**Data**: Empty object

#### 5. `error` - Error Occurred
Indicates an error occurred during processing.

```
event: error
data: {
  "error": "Failed to execute tool: API key missing"
}
```

**Data**: Object with error message

## Frontend Implementation

### Basic EventSource Setup

```javascript
const response = await fetch(`/api/conversation/${conversationId}`, {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': `Bearer ${userToken}`
  },
  body: JSON.stringify({
    message: "Show me my Wildberries products",
    stream: true
  })
});

// The response body is the SSE stream
const reader = response.body.getReader();
const decoder = new TextDecoder();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  
  const chunk = decoder.decode(value);
  // Process SSE events from chunk
}
```

### Complete Event Handler

```javascript
class StreamHandler {
  constructor(conversationContainer) {
    this.container = conversationContainer;
    this.currentMessage = '';
    this.messageElement = null;
  }

  async processStream(conversationId, message) {
    const response = await fetch(`/api/conversation/${conversationId}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.userToken}`
      },
      body: JSON.stringify({
        message: message,
        stream: true
      })
    });

    const reader = response.body.getReader();
    const decoder = new TextDecoder();
    let buffer = '';

    this.showTypingIndicator();

    try {
      while (true) {
        const { done, value } = await reader.read();
        if (done) break;
        
        buffer += decoder.decode(value, { stream: true });
        const events = this.parseSSEEvents(buffer);
        
        for (const event of events.complete) {
          this.handleEvent(event);
        }
        
        buffer = events.incomplete;
      }
    } catch (error) {
      this.showError('Connection error occurred');
    }
  }

  parseSSEEvents(buffer) {
    const events = buffer.split('\n\n');
    const incomplete = events.pop(); // Last item might be incomplete
    const complete = [];

    for (const eventStr of events) {
      if (!eventStr.trim()) continue;
      
      const lines = eventStr.split('\n');
      const event = {};
      
      for (const line of lines) {
        if (line.startsWith('event: ')) {
          event.type = line.substring(7);
        } else if (line.startsWith('data: ')) {
          event.data = line.substring(6);
        }
      }
      
      if (event.type && event.data) {
        complete.push(event);
      }
    }

    return { complete, incomplete };
  }

  handleEvent(event) {
    switch (event.type) {
      case 'conversationId':
        const conversationId = JSON.parse(event.data);
        this.onConversationId(conversationId);
        break;
        
      case 'chunk':
        const content = JSON.parse(event.data);
        this.appendToMessage(content);
        break;
        
      case 'tool_execution':
        const toolData = JSON.parse(event.data);
        this.showToolExecutionStatus(toolData.message, toolData.toolCalls);
        break;
        
      case 'tool_complete':
        const processData = JSON.parse(event.data);
        this.showProcessingStatus(processData.message);
        break;
        
      case 'end':
        this.finishMessage();
        break;
        
      case 'error':
        const errorData = JSON.parse(event.data);
        this.showError(errorData.error);
        break;
    }
  }

  showTypingIndicator() {
    this.messageElement = document.createElement('div');
    this.messageElement.className = 'ai-message streaming';
    this.messageElement.innerHTML = '<div class="typing-dots">‚óè‚óè‚óè</div>';
    this.container.appendChild(this.messageElement);
  }

  appendToMessage(content) {
    if (!this.messageElement) {
      this.messageElement = document.createElement('div');
      this.messageElement.className = 'ai-message streaming';
      this.container.appendChild(this.messageElement);
    }
    
    this.currentMessage += content;
    this.messageElement.innerHTML = this.formatMessage(this.currentMessage);
    this.scrollToBottom();
  }

  showToolExecutionStatus(message, toolCalls) {
    const statusElement = document.createElement('div');
    statusElement.className = 'tool-status executing';
    statusElement.innerHTML = `
      <div class="status-icon">üîÑ</div>
      <div class="status-text">${message}</div>
      <div class="tool-list">${toolCalls.join(', ')}</div>
    `;
    this.container.appendChild(statusElement);
    this.scrollToBottom();
  }

  showProcessingStatus(message) {
    const statusElement = document.createElement('div');
    statusElement.className = 'tool-status processing';
    statusElement.innerHTML = `
      <div class="status-icon">‚öôÔ∏è</div>
      <div class="status-text">${message}</div>
    `;
    this.container.appendChild(statusElement);
    this.scrollToBottom();
  }

  finishMessage() {
    if (this.messageElement) {
      this.messageElement.classList.remove('streaming');
      this.messageElement.classList.add('complete');
    }
    this.removeStatusElements();
  }

  showError(errorMessage) {
    const errorElement = document.createElement('div');
    errorElement.className = 'error-message';
    errorElement.textContent = `Error: ${errorMessage}`;
    this.container.appendChild(errorElement);
  }

  removeStatusElements() {
    const statusElements = this.container.querySelectorAll('.tool-status');
    statusElements.forEach(el => el.remove());
  }

  formatMessage(text) {
    // Format markdown, line breaks, etc.
    return text.replace(/\n/g, '<br>');
  }

  scrollToBottom() {
    this.container.scrollTop = this.container.scrollHeight;
  }

  onConversationId(conversationId) {
    // Store conversation ID for later use (e.g., URL updates, saving state)
    this.conversationId = conversationId;
    console.log('Conversation ID:', conversationId);
    
    // Optionally update the URL or store in local state
    // window.history.pushState({}, '', `/chat/${conversationId}`);
  }
}
```

### React Implementation

```jsx
import { useEffect, useState } from 'react';

function ChatStream({ conversationId, message }) {
  const [content, setContent] = useState('');
  const [status, setStatus] = useState(null);
  const [isComplete, setIsComplete] = useState(false);

  useEffect(() => {
    async function processStream() {
      const response = await fetch(`/api/conversation/${conversationId}`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${userToken}`
        },
        body: JSON.stringify({
          message: message,
          stream: true
        })
      });

      const reader = response.body.getReader();
      const decoder = new TextDecoder();
      let buffer = '';

      try {
        while (true) {
          const { done, value } = await reader.read();
          if (done) break;
          
          buffer += decoder.decode(value, { stream: true });
          const events = parseSSEEvents(buffer);
          
          for (const event of events.complete) {
            handleEvent(event);
          }
          
          buffer = events.incomplete;
        }
      } catch (error) {
        console.error('Stream error:', error);
        setStatus({ type: 'error', message: 'Connection error' });
      }
    }

    function handleEvent(event) {
      switch (event.type) {
        case 'conversationId':
          const conversationId = JSON.parse(event.data);
          // Handle conversationId event
          break;
          
        case 'chunk':
          const chunk = JSON.parse(event.data);
          setContent(prev => prev + chunk);
          break;
          
        case 'tool_execution':
          const data = JSON.parse(event.data);
          setStatus({
            type: 'executing',
            message: data.message,
            tools: data.toolCalls
          });
          break;
          
        case 'tool_complete':
          const processData = JSON.parse(event.data);
          setStatus({
            type: 'processing',
            message: processData.message
          });
          break;
          
        case 'end':
          setIsComplete(true);
          setStatus(null);
          break;
          
        case 'error':
          const errorData = JSON.parse(event.data);
          setStatus({
            type: 'error',
            message: errorData.error
          });
          break;
      }
    }

    processStream();
  }, [conversationId, message]);

  return (
    <div className="chat-message">
      {status && (
        <div className={`status ${status.type}`}>
          {status.type === 'executing' && 'üîÑ'}
          {status.type === 'processing' && '‚öôÔ∏è'}
          {status.type === 'error' && '‚ùå'}
          {status.message}
          {status.tools && (
            <div className="tool-list">
              Tools: {status.tools.join(', ')}
            </div>
          )}
        </div>
      )}
      <div className={`message-content ${isComplete ? 'complete' : 'streaming'}`}>
        {content}
      </div>
    </div>
  );
}
```

### CSS Styling

```css
.ai-message.streaming {
  border-left: 3px solid #007bff;
  animation: pulse 2s infinite;
}

.tool-status {
  display: flex;
  align-items: center;
  gap: 8px;
  padding: 8px 12px;
  margin: 4px 0;
  border-radius: 6px;
  font-size: 14px;
  background-color: #f8f9fa;
  border: 1px solid #dee2e6;
}

.tool-status.executing {
  background-color: #e3f2fd;
  color: #1976d2;
  border-color: #90caf9;
}

.tool-status.processing {
  background-color: #f3e5f5;
  color: #7b1fa2;
  border-color: #ce93d8;
}

.tool-status.error {
  background-color: #ffebee;
  color: #d32f2f;
  border-color: #ef9a9a;
}

.status-icon {
  animation: spin 1s linear infinite;
}

.tool-list {
  font-size: 12px;
  opacity: 0.8;
  margin-left: auto;
}

@keyframes pulse {
  0%, 100% { opacity: 1; }
  50% { opacity: 0.7; }
}

@keyframes spin {
  from { transform: rotate(0deg); }
  to { transform: rotate(360deg); }
}
```

## Chain of Thoughts Flow

The typical flow for a tool-enabled conversation:

1. **User sends message**: "Show me my Wildberries products"
2. **AI initial thinking**: `chunk` events with "I'll help you check your inventory..."
3. **Tool execution notice**: `tool_execution` event with execution status
4. **Tool processing**: `tool_complete` event indicating processing
5. **Final response**: More `chunk` events with actual product data
6. **Stream complete**: `end` event

## Example Complete Flow

```
‚Üí User: "Show me my top selling products" (new conversation)

‚Üê event: conversationId
  data: "conv_abc123def456"

‚Üê event: chunk
  data: "I'll help you analyze your top selling products."

‚Üê event: chunk  
  data: " Let me fetch your current Wildberries inventory data..."

‚Üê event: tool_execution
  data: {
    "message": "Let me fetch your Wildberries product data...",
    "toolCalls": ["wildberries_seller_products"]
  }

‚Üê event: tool_complete
  data: {
    "message": "Processing results..."
  }

‚Üê event: chunk
  data: "Based on your Wildberries data, here are your top performing products:\n\n"

‚Üê event: chunk
  data: "1. **Product A** - 150 sales this month\n"

‚Üê event: chunk
  data: "2. **Product B** - 120 sales this month\n"

‚Üê event: end
  data: {}
```

This creates a natural, engaging conversation flow that keeps users informed throughout the entire process, making the AI feel more intelligent and trustworthy. 